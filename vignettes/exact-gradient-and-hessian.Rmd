---
title: "ERGM equations"
author: "George G Vega Yon"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{ERGM equations}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
\newcommand{\Graph}{\mathbf{Y}}
\newcommand{\GRAPH}{\mathcal{Y}}
\newcommand{\graph}{\mathbf{y}}
\newcommand{\Pr}[1]{\text{P}\left(#1\right)}
\newcommand{\Prcond}[2]{\Pr{\left.#1\vphantom{#2}\right|\vphantom{#1}#2}}
\renewcommand{\exp}[1]{\text{exp}\left\{#1\right\}}
\renewcommand{\log}[1]{\text{log}\left(#1\right)}
\newcommand{\s}[1]{g\left(#1\right)}
\newcommand{\SUFF}{\mathcal{S}}
\newcommand{\Suff}{\mathbf{S}}
\newcommand{\suff}{\mathbf{s}}
\newcommand{\t}[1]{{#1}^{\text{t}}}
\newcommand{\beta}{\theta}
\newcommand{\weight}{w}
\newcommand{\Weight}{\mathbf{W}}

The likelihood (probability function) of an Exponential Random Graph Model (ERGM) is defined as follows:

$$
\Prcond{\Graph = \graph}{X = x} = \frac{%
  \exp{\t{\beta}\s{\graph, x}} %
  }{%
  \sum_{\graph'\in\GRAPH} \exp{\t{\beta}\s{\graph', x}} %
  },\quad \forall \graph\in\GRAPH
$$

Where $\graph\in\GRAPH$ is a random graph, $X$ is a vector of attributes,
$\beta$ is a column-vector of length $k$ (model parameters), and $\s{\cdot}$ is a
function that returns a column-vector of sufficient statistics, also of length $k$.

In the case of `ergmito`, we usually look at a pooled model with $n$ networks, i.e.

$$
\prod_{i \in N}\Prcond{\Graph = \graph_i}{X = x_i} = \prod_{i \in N}\frac{%
  \exp{\t{\beta}\s{\graph_i, x_i}} %
  }{%
  \sum_{\graph_i'\in\GRAPH} \exp{\t{\beta}\s{\graph_i', x_i}} %
  },\quad \forall \graph_i\in\GRAPH
$$

Where $N\equiv\{1,\dots, n\}$ is a vector of indices. 

## log-likelihood

In the case of a single network, the model's log-likelihood is given by

$$
\log{\Pr{\cdot}} = \t{\beta}\s{\graph, x} - %
  \log{ % 
    \sum_{\graph'\in\Graph}\exp{\t{\beta}\s{\graph', x}} %
    }
$$
In general, we can reduce the computational complexity of this calculation by
looking at the isomorphic sufficient statistics, this is, group up elements
based on the set of unique vectors of sufficient statistics. 

$$
\t{\beta}\s{\graph, x} - %
  \log{ % 
    \sum_{\suff\in\SUFF}\weight_\suff \exp{\t{\beta}\suff} %
    }
$$

Where $\suff\in\SUFF$ is a vector of sufficient statistics, 
$\weight_\suff\equiv|\left\{\graph\in\GRAPH: \s{\graph,x} = \suff\right\}|$ is
the number of networks in $\GRAPH$ which sufficient statistics equal $\suff$.
We can write this in matrix form:

$$
\t{\beta}\s{\graph, x} - %
  \log{ % 
    \Weight \times \exp{\Suff\times \beta}  %
    }
$$


## Gradient

$$
\frac{\delta}{\delta\theta_k}\log{\Pr{\cdot}} = s_k(g) - \frac{\sum_{g'}s_k(g')\exp{\theta^ts(g')}}{\sum_{g'}\exp{\theta^ts(g')}},\quad\forall k
$$

Considering the iso statistics, we can simplify the summation by grouping, in particular, let $H$ be the set of all unique sets of statistics in $s(\cdot)$ and $w_h$ the size of the $h$-th group, then

$$
\frac{\delta}{\delta\theta_k}\log{\Pr{\cdot}} = s_k(g) - \frac{\sum_{h}w_hs_k(g_h)\exp{\theta^ts(g_h)}}{\sum_{h}w_h\exp{\theta^ts(g_h)}},\quad\forall k
$$

Where $g_h$ is any graph in the group $h$. We can write this in matrix form

$$
\nabla \log{\Pr{\cdot}} = s^t(g) - s^t(\cdot)\left[W\circ\exp{s(\cdot)\theta}\right]/\lambda(\theta)
$$

Where $s(\cdot)$ is a $|H|\times K$ matrix of sufficient statistics, $\lambda(\theta)$  is the normalizing constant, and $\circ$ is the element wise-product.

## Hessian

In the case of the hessian, we have that $\frac{\delta^2}{\delta\theta_k\delta\theta_u}\log{\Pr{\cdot}}$ equals:

$$
-\frac{\left(\sum_{g'}s_k(g')s_u(g')\exp{\theta^ts(g')}\right)\left(\sum_{g'}\exp{\theta^ts(g')}\right) - \left(\sum_{g'}s_k(g')\exp{\theta^ts(g')}\right)\left(\sum_{g'}s_u(g')\exp{\theta^ts(g')}\right)}{\left(\sum_{g'}\exp{\theta^ts(g')}\right)^2}
$$

For all $k,u$. Once again, we can simplify this using matrix notation and noticing the fact that we can group the sufficient statistics using iso-statistics

$$
-\frac{W^t\left[s_k(\cdot)\circ s_u(\cdot)\circ \exp{s(\cdot)\theta}\right]\lambda(\theta) -\left( W^t\left[s_k(\cdot)\circ \exp{s(\cdot)\theta}\right]\right)\left(W^t\left[s_u(\cdot)\circ \exp{s(\cdot)\theta}\right]\right) }{\lambda(\theta)^2}
$$